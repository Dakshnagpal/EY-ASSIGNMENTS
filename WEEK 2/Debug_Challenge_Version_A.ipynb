{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug Challenge - Team Model\n",
    "## Interactive Activity: Find and Fix the Bug!\n",
    "\n",
    "**Your Task**: This logistic regression model has a bug that prevents it from training properly. \n",
    "\n",
    "**Instructions**:\n",
    "1. Run all the cells\n",
    "2. Observe what happens\n",
    "3. Find the bug\n",
    "4. Fix it\n",
    "5. Explain to the class what was wrong\n",
    "\n",
    "**Hints**: \n",
    "- Watch the cost values carefully\n",
    "- What should happen to cost during training?\n",
    "- Are there any unusual patterns?\n",
    "\n",
    "Good luck! ðŸ›ðŸ”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load & Prepare Dataset\n",
    "Create synthetic binary classification data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic binary classification dataset\n",
    "m_train = 200  # number of training examples\n",
    "m_test = 50    # number of test examples\n",
    "n_features = 50  # number of features\n",
    "\n",
    "# Generate random training data\n",
    "X_train = np.random.randn(n_features, m_train)\n",
    "y_train = (np.random.rand(1, m_train) > 0.5).astype(int)\n",
    "\n",
    "# Generate random test data\n",
    "X_test = np.random.randn(n_features, m_test)\n",
    "y_test = (np.random.rand(1, m_test) > 0.5).astype(int)\n",
    "\n",
    "# Display dataset information\n",
    "print(f\"Training set: X_train.shape = {X_train.shape}, y_train.shape = {y_train.shape}\")\n",
    "print(f\"Test set: X_test.shape = {X_test.shape}, y_test.shape = {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define Helper Functions\n",
    "Core functions for sigmoid activation and parameter initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"Compute sigmoid activation function: 1/(1+e^-z)\"\"\"\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_features):\n",
    "    \"\"\"Initialize weights (zeros) and bias to zero\"\"\"\n",
    "    w = np.zeros((n_features, 1))\n",
    "    b = 0.0\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(w, b, X, y):\n",
    "    \"\"\"Forward and backward propagation for logistic regression\"\"\"\n",
    "    m = X.shape[1]  # number of training examples\n",
    "    \n",
    "    # Forward propagation: compute predictions\n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    \n",
    "    # Compute binary cross-entropy cost\n",
    "    cost = -1/m * np.sum(y * np.log(A) + (1 - y) * np.log(1 - A))\n",
    "    \n",
    "    # Backward propagation: compute gradients\n",
    "    dw = 1/m * np.dot(X, (A - y).T)\n",
    "    db = 1/m * np.sum(A - y)\n",
    "    \n",
    "    grads = {\"dw\": dw, \"db\": db}\n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Implement Training Function\n",
    "Use gradient descent to optimize weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(w, b, X, y, num_iterations, learning_rate, print_cost=True):\n",
    "    \"\"\"Train model using gradient descent optimization\"\"\"\n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        # Compute gradients and cost\n",
    "        grads, cost = propagate(w, b, X, y)\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # Update parameters using learning rate\n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "        \n",
    "        # Store cost for plotting\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "        # Print progress\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(f\"Cost after iteration {i}: {cost}\")\n",
    "    \n",
    "    params = {\"w\": w, \"b\": b}\n",
    "    return params, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, X):\n",
    "    \"\"\"Predict class labels (0 or 1) based on trained parameters\"\"\"\n",
    "    m = X.shape[1]  # number of examples\n",
    "    y_pred = np.zeros((1, m))\n",
    "    \n",
    "    # Compute predictions\n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    \n",
    "    # Convert probabilities to binary labels (threshold = 0.5)\n",
    "    for i in range(A.shape[1]):\n",
    "        y_pred[0, i] = 1 if A[0, i] > 0.5 else 0\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train the Model\n",
    "Initialize parameters and train using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights and bias to zero\n",
    "w, b = initialize_parameters(n_features)\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 5.0\n",
    "num_iterations = 2000\n",
    "\n",
    "# Train the logistic regression model\n",
    "print(\"Training the model...\\n\")\n",
    "# Train the model and get the learned parameters and cost history\n",
    "params, costs = train(w, b, X_train, y_train, num_iterations, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Visualize Training Progress\n",
    "Plot the learning curve to see cost decrease over iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training cost over iterations\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(costs, linewidth=2)\n",
    "plt.ylabel('Cost (Loss)', fontsize=12)\n",
    "plt.xlabel('Iterations (hundreds)', fontsize=12)\n",
    "plt.title('Learning Curve - Cost vs Iterations', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate Model Performance\n",
    "Make predictions and calculate accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "y_pred_train = predict(params[\"w\"], params[\"b\"], X_train)\n",
    "y_pred_test = predict(params[\"w\"], params[\"b\"], X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = 100 - np.mean(np.abs(y_pred_train - y_train)) * 100\n",
    "test_accuracy = 100 - np.mean(np.abs(y_pred_test - y_test)) * 100\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ¯ Challenge Questions\n",
    "\n",
    "Once you've fixed the bug, answer these:\n",
    "\n",
    "1. **What was the bug?**\n",
    "   - Write your answer here:\n",
    "\n",
    "2. **How did you identify it?**\n",
    "   - Write your answer here:\n",
    "\n",
    "3. **Why did it cause the specific problem?**\n",
    "   - Write your answer here:\n",
    "\n",
    "4. **What learning rate worked best?**\n",
    "   - Write your answer here:\n",
    "\n",
    "5. **What accuracy did you achieve?**\n",
    "   - Train: _____%\n",
    "   - Test: _____%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
